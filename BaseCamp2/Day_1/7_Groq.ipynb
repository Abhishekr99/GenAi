{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groq Usage for LLM ###\n",
    "**Library Need**  \n",
    "To use the APIs provided by the groq platform, the library 'groq' is required.  \n",
    "Ensure to have performed 'pip install groq'  \n",
    "The API key from your Groq account would be required to execute this code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required class from Groq\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Initialise an client object with API key\n",
    "load_dotenv ()\n",
    "Client = Groq ()\n",
    "\n",
    "# Client = Groq (api_key='Your API Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoke for chat Completion**  \n",
    ">The APIs can be used for invoking LLM models available in Groq for chat completion  \n",
    ">Try with differet models and different prompt messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One interesting fact about LLAMA is that it stands for \"Large Language Model Meta AI.\" LLAMA is an artificial intelligence model developed by Meta, designed to process and generate human-like language. It's a type of chatbot that can understand and respond to a wide range of questions and topics, using a massive dataset of text from the internet to learn and improve its responses.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me interesting fact about LLAMA\"\n",
    "\n",
    "# Prompt needs to be organised as message (list of dict)\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    }\n",
    "]\n",
    "completion = Client.chat.completions.create(\n",
    "    messages=messages,    \n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    # model=\"openai/gpt-oss-120b\",\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "print (completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models:\n",
    "https://console.groq.com/docs/models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_basecamp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
